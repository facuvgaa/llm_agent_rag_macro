# Agent Full - Sistema RAG Banco Macro

Sistema de Retrieval Augmented Generation (RAG) para el Banco Macro que permite hacer consultas sobre documentos usando Inteligencia Artificial.

## ğŸ¥ Demo del Sistema

![Demo del Sistema RAG](docs/gifs/GrabaciÃ³n-de-pantalla-desde-2025-11-05-03-39-45.gif)

*Demo visual del sistema RAG en funcionamiento*

## ğŸ“‹ Arquitectura del Sistema

![Diagrama de Arquitectura](docs/images/arquitectura-rag.excalidraw)

El sistema estÃ¡ compuesto por dos partes principales:

### 1. ETL (Extract, Transform, Load)
- **Leer URLs**: Lee URLs de documentos desde `services/airflow_dags/urls.txt`
- **Chunkear PDFs**: Divide los PDFs en chunks mÃ¡s pequeÃ±os usando [pdf-chunk-flow](https://pypi.org/project/pdf-chunk-flow/)
- **Generar Embeddings**: Convierte los chunks en vectores de 768 dimensiones usando [embedding-flow](https://pypi.org/project/embedding-flow/)
- **Publicar a Kafka**: Notifica cuando el proceso ETL estÃ¡ completo
- **Almacenar en Qdrant**: Guarda los embeddings en la base de datos vectorial (usando embedding-flow)

### 2. RAG System
- **API Gateway**: Punto de entrada para las consultas de los usuarios
- **LangChains Service**: Orquestador central que coordina todo el flujo
- **Embedding Service**: Genera embeddings de las consultas de los usuarios
- **Qdrant Service**: Base de datos vectorial para bÃºsqueda semÃ¡ntica
- **Redis**: Cache y memoria de conversaciones
- **LLM Service (Ollama)**: Modelo de lenguaje para generar respuestas

## ğŸš€ Inicio RÃ¡pido

### InstalaciÃ³n de Prerequisitos

Si no tienes Docker y Docker Compose instalados, ejecuta:

```bash
# Instalar Docker y Docker Compose automÃ¡ticamente
./scripts/install_docker.sh
```

Este script:
- âœ… Detecta tu sistema operativo
- âœ… Instala Docker si no estÃ¡ instalado
- âœ… Instala Docker Compose v2 (plugin)
- âœ… Configura tu usuario para usar Docker sin sudo
- âœ… Habilita Docker al inicio del sistema

**Nota:** DespuÃ©s de ejecutar el script, si te agregÃ³ al grupo docker, cierra sesiÃ³n y vuelve a iniciar, o ejecuta `newgrp docker`.

### ConfiguraciÃ³n de Variables de Entorno

```bash
# Copiar archivos de ejemplo
cp environment_variables/.env.rag.example environment_variables/.env.rag
cp environment_variables/.env.qdrant.example environment_variables/.env.qdrant

# Ajustar valores si es necesario (los defaults funcionan para desarrollo)
```

### Levantar servicios

```bash
# Levantar stack ETL
make etl-up

# Levantar stack RAG
make rag-up
```

### Detener servicios

```bash
# Detener stack ETL
make etl-down

# Detener stack RAG
make rag-down
```

## ğŸŒ Acceso a los Servicios

Una vez levantados los servicios, puedes acceder a:

| Servicio | URL | DescripciÃ³n |
|----------|-----|-------------|
| **Frontend** | http://localhost:3000 | Interfaz web del chatbot RAG |
| **API Gateway** | http://localhost:8000 | API REST para consultas RAG |
| **Airflow (ETL)** | http://localhost:8080 | Interfaz web de Airflow para gestionar DAGs |
| **Qdrant** | http://localhost:6333 | Interfaz web de Qdrant (base de datos vectorial) |
| **LangChains Service** | http://localhost:8002 | Servicio RAG directamente |
| **Embedding Service** | http://localhost:8001 | Servicio de embeddings |
| **Ollama** | http://localhost:11434 | API de Ollama |

**Nota:** Los servicios internos (Redis, etc.) no estÃ¡n expuestos externamente por seguridad.

## ğŸ“ Estructura del Proyecto

```
agent-full/
â”œâ”€â”€ infra/
â”‚   â”œâ”€â”€ docker-compose.etl.yml    # Servicios ETL
â”‚   â””â”€â”€ docker-compose.rag.yml     # Servicios RAG
â”œâ”€â”€ services/
â”‚   â”œâ”€â”€ api_gateway/              # API Gateway
â”‚   â”œâ”€â”€ langchains_service/       # Servicio RAG principal
â”‚   â”œâ”€â”€ embedding_service/        # GeneraciÃ³n de embeddings
â”‚   â”œâ”€â”€ airflow_dags/             # DAGs de Airflow para ETL
â”‚   â””â”€â”€ ...
â”œâ”€â”€ docker/                        # Dockerfiles de servicios
â”œâ”€â”€ docs/                          # DocumentaciÃ³n
â”‚   â””â”€â”€ images/                    # Diagramas y diagramas
â””â”€â”€ environment_variables/         # Variables de entorno
```

## ğŸ”§ ConfiguraciÃ³n

### Variables de Entorno

Ver `environment_variables/.env.rag` y `environment_variables/.env.qdrant` para configurar las variables de entorno necesarias.

### PersonalizaciÃ³n de PDFs

Para agregar o modificar los PDFs que se procesan en el ETL, edita el archivo:

```
services/airflow_dags/urls.txt
```

Cada lÃ­nea del archivo debe contener una URL vÃ¡lida de un PDF. El DAG de Airflow procesarÃ¡ todos los PDFs listados en este archivo.

## ğŸ› ï¸ TecnologÃ­as y LibrerÃ­as

### Stack TecnolÃ³gico Principal

- **Backend**:
  - **Python 3.12+**: Lenguaje principal para servicios backend
  - **FastAPI**: Framework web para API Gateway y servicios
  - **Uvicorn**: Servidor ASGI para FastAPI
  - **LangChain/LangGraph**: Framework para orquestaciÃ³n RAG y flujos de trabajo
  - **LangChain Ollama**: IntegraciÃ³n con Ollama para modelos locales

- **Frontend**:
  - **Next.js**: Framework React para la interfaz de usuario
  - **React**: Biblioteca para interfaces de usuario
  - **TypeScript**: Tipado estÃ¡tico para JavaScript
  - **Tailwind CSS**: Framework CSS para estilos

- **Bases de Datos y Almacenamiento**:
  - **Qdrant**: Base de datos vectorial para bÃºsqueda semÃ¡ntica
  - **Redis**: Cache y memoria de conversaciones
  - **Supabase**: Backend como servicio (PostgreSQL) para el frontend

- **Infraestructura y OrquestaciÃ³n**:
  - **Docker & Docker Compose**: ContenedorizaciÃ³n y orquestaciÃ³n
  - **Airflow**: OrquestaciÃ³n de workflows ETL
  - **Kafka**: MensajerÃ­a y eventos asÃ­ncronos

- **Modelos de IA**:
  - **Ollama**: Servidor para ejecutar modelos LLM localmente
  - **llama3.2:3b**: Modelo de lenguaje utilizado

### Procesamiento de PDFs y Embeddings

El sistema utiliza librerÃ­as propias desarrolladas especÃ­ficamente para este proyecto:

- **[pdf-chunk-flow](https://pypi.org/project/pdf-chunk-flow/)**: LibrerÃ­a para chunkear PDFs
  - Utilizada para dividir documentos PDF en chunks mÃ¡s pequeÃ±os
  - ConfiguraciÃ³n: **768 dimensiones** con **overlap activado** para mejorar la coherencia contextual

- **[embedding-flow](https://pypi.org/project/embedding-flow/)**: LibrerÃ­a para generar embeddings y cargar en Qdrant
  - Genera embeddings vectoriales de los chunks
  - Carga automÃ¡tica de embeddings en Qdrant
  - ConfiguraciÃ³n: **768 dimensiones** (compatible con el modelo de embeddings usado)

### Modelo de Lenguaje

- **LLM**: `llama3.2:3b` ejecutÃ¡ndose en Ollama
  - Modelo de lenguaje pequeÃ±o y eficiente para generaciÃ³n de respuestas
  - Configurado en `services/langchains_service/chain/rag_chain.py`

## ğŸ“š DocumentaciÃ³n

- Diagrama de arquitectura: `docs/images/arquitectura-rag.excalidraw`

## ğŸ™ Agradecimientos

Este proyecto utiliza el frontend de [Chatbot UI](https://github.com/mckaywrigley/chatbot-ui) desarrollado por [mckaywrigley](https://github.com/mckaywrigley). Agradecemos su excelente trabajo y contribuciÃ³n a la comunidad open source.

## ğŸ‘¤ Autor

**Facundo Vega**

Desarrollador del sistema RAG y las librerÃ­as utilizadas en este proyecto.

### ğŸ”— Redes y Contacto

- **LinkedIn**: [wfvega](https://www.linkedin.com/in/wfvega/)

### ğŸ“¦ LibrerÃ­as Propias

Este proyecto utiliza librerÃ­as desarrolladas por el autor:

- **PyPI**: [facuvega](https://pypi.org/user/facuvega/)
  - Todas las librerÃ­as disponibles en PyPI
- **GitHub**: [facuvegaingenieer](https://github.com/facuvegaingenieer)
  - Repositorios de las librerÃ­as:
    - [pdf-chunk-flow](https://github.com/facuvegaingenieer/pdf_chunk_flow)
    - [embedding-flow](https://github.com/facuvegaingenieer/macro-embedding-flow)
    - Y mÃ¡s...

## ğŸ“„ Licencia

Este proyecto estÃ¡ bajo la Licencia MIT. Ver el archivo [LICENSE](LICENSE) para mÃ¡s detalles.

---

# Agent Full - Macro Bank RAG System

RAG (Retrieval Augmented Generation) system for Macro Bank that allows querying documents using Artificial Intelligence.

## ğŸ¥ System Demo

![RAG System Demo](docs/gifs/GrabaciÃ³n-de-pantalla-desde-2025-11-05-03-39-45.gif)

*Visual demo of the RAG system in operation*

## ğŸ“‹ System Architecture

![Architecture Diagram](docs/images/arquitectura-rag.excalidraw)

The system consists of two main parts:

### 1. ETL (Extract, Transform, Load)
- **Read URLs**: Reads document URLs from `services/airflow_dags/urls.txt`
- **Chunk PDFs**: Divides PDFs into smaller chunks using [pdf-chunk-flow](https://pypi.org/project/pdf-chunk-flow/)
- **Generate Embeddings**: Converts chunks into 768-dimensional vectors using [embedding-flow](https://pypi.org/project/embedding-flow/)
- **Publish to Kafka**: Notifies when the ETL process is complete
- **Store in Qdrant**: Saves embeddings in the vector database (using embedding-flow)

### 2. RAG System
- **API Gateway**: Entry point for user queries
- **LangChains Service**: Central orchestrator that coordinates the entire flow
- **Embedding Service**: Generates embeddings for user queries
- **Qdrant Service**: Vector database for semantic search
- **Redis**: Cache and conversation memory
- **LLM Service (Ollama)**: Language model for generating responses

## ğŸš€ Quick Start

### Prerequisites Installation

If you don't have Docker and Docker Compose installed, run:

```bash
# Automatically install Docker and Docker Compose
./scripts/install_docker.sh
```

This script:
- âœ… Detects your operating system
- âœ… Installs Docker if not installed
- âœ… Installs Docker Compose v2 (plugin)
- âœ… Configures your user to use Docker without sudo
- âœ… Enables Docker on system startup

**Note:** After running the script, if it added you to the docker group, log out and log back in, or run `newgrp docker`.

### Environment Variables Configuration

```bash
# Copy example files
cp environment_variables/.env.rag.example environment_variables/.env.rag
cp environment_variables/.env.qdrant.example environment_variables/.env.qdrant

# Adjust values if necessary (defaults work for development)
```

### Start Services

```bash
# Start ETL stack
make etl-up

# Start RAG stack
make rag-up
```

### Stop Services

```bash
# Stop ETL stack
make etl-down

# Stop RAG stack
make rag-down
```

## ğŸŒ Service Access

Once services are up, you can access:

| Service | URL | Description |
|---------|-----|-------------|
| **Frontend** | http://localhost:3000 | RAG chatbot web interface |
| **API Gateway** | http://localhost:8000 | REST API for RAG queries |
| **Airflow (ETL)** | http://localhost:8080 | Airflow web interface for managing DAGs |
| **Qdrant** | http://localhost:6333 | Qdrant web interface (vector database) |
| **LangChains Service** | http://localhost:8002 | RAG service directly |
| **Embedding Service** | http://localhost:8001 | Embedding service |
| **Ollama** | http://localhost:11434 | Ollama API |

**Note:** Internal services (Redis, etc.) are not exposed externally for security.

## ğŸ“ Project Structure

```
agent-full/
â”œâ”€â”€ infra/
â”‚   â”œâ”€â”€ docker-compose.etl.yml    # ETL services
â”‚   â””â”€â”€ docker-compose.rag.yml     # RAG services
â”œâ”€â”€ services/
â”‚   â”œâ”€â”€ api_gateway/              # API Gateway
â”‚   â”œâ”€â”€ langchains_service/       # Main RAG service
â”‚   â”œâ”€â”€ embedding_service/        # Embedding generation
â”‚   â”œâ”€â”€ airflow_dags/             # Airflow DAGs for ETL
â”‚   â””â”€â”€ ...
â”œâ”€â”€ docker/                        # Service Dockerfiles
â”œâ”€â”€ docs/                          # Documentation
â”‚   â””â”€â”€ images/                    # Diagrams and images
â””â”€â”€ environment_variables/         # Environment variables
```

## ğŸ”§ Configuration

### Environment Variables

See `environment_variables/.env.rag` and `environment_variables/.env.qdrant` to configure the necessary environment variables.

### PDF Customization

To add or modify PDFs processed in the ETL, edit the file:

```
services/airflow_dags/urls.txt
```

Each line of the file must contain a valid PDF URL. The Airflow DAG will process all PDFs listed in this file.

## ğŸ› ï¸ Technologies and Libraries

### Main Technology Stack

- **Backend**:
  - **Python 3.12+**: Main language for backend services
  - **FastAPI**: Web framework for API Gateway and services
  - **Uvicorn**: ASGI server for FastAPI
  - **LangChain/LangGraph**: Framework for RAG orchestration and workflows
  - **LangChain Ollama**: Integration with Ollama for local models

- **Frontend**:
  - **Next.js**: React framework for user interface
  - **React**: Library for user interfaces
  - **TypeScript**: Static typing for JavaScript
  - **Tailwind CSS**: CSS framework for styling

- **Databases and Storage**:
  - **Qdrant**: Vector database for semantic search
  - **Redis**: Cache and conversation memory
  - **Supabase**: Backend as a service (PostgreSQL) for frontend

- **Infrastructure and Orchestration**:
  - **Docker & Docker Compose**: Containerization and orchestration
  - **Airflow**: ETL workflow orchestration
  - **Kafka**: Messaging and asynchronous events

- **AI Models**:
  - **Ollama**: Server for running LLM models locally
  - **llama3.2:3b**: Language model used

### PDF Processing and Embeddings

The system uses custom libraries developed specifically for this project:

- **[pdf-chunk-flow](https://pypi.org/project/pdf-chunk-flow/)**: Library for chunking PDFs
  - Used to divide PDF documents into smaller chunks
  - Configuration: **768 dimensions** with **overlap enabled** to improve contextual coherence

- **[embedding-flow](https://pypi.org/project/embedding-flow/)**: Library for generating embeddings and loading into Qdrant
  - Generates vector embeddings of chunks
  - Automatic loading of embeddings into Qdrant
  - Configuration: **768 dimensions** (compatible with the embedding model used)

### Language Model

- **LLM**: `llama3.2:3b` running on Ollama
  - Small and efficient language model for response generation
  - Configured in `services/langchains_service/chain/rag_chain.py`

## ğŸ“š Documentation

- Architecture diagram: `docs/images/arquitectura-rag.excalidraw`

## ğŸ™ Acknowledgments

This project uses the frontend from [Chatbot UI](https://github.com/mckaywrigley/chatbot-ui) developed by [mckaywrigley](https://github.com/mckaywrigley). We thank them for their excellent work and contribution to the open source community.

## ğŸ‘¤ Author

**Facundo Vega**

Developer of the RAG system and libraries used in this project.

### ğŸ”— Networks and Contact

- **LinkedIn**: [wfvega](https://www.linkedin.com/in/wfvega/)

### ğŸ“¦ Custom Libraries

This project uses libraries developed by the author:

- **PyPI**: [facuvega](https://pypi.org/user/facuvega/)
  - All libraries available on PyPI
- **GitHub**: [facuvegaingenieer](https://github.com/facuvegaingenieer)
  - Library repositories:
    - [pdf-chunk-flow](https://github.com/facuvegaingenieer/pdf_chunk_flow)
    - [embedding-flow](https://github.com/facuvegaingenieer/macro-embedding-flow)
    - And more...

## ğŸ“„ License

This project is licensed under the MIT License. See the [LICENSE](LICENSE) file for more details.
