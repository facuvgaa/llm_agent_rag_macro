# üìä Informe T√©cnico: Macro RAG - An√°lisis Profundo del Proyecto

## üìã Tabla de Contenidos
1. [Visi√≥n General de Arquitectura](#visi√≥n-general-de-arquitectura)
2. [Flujos Funcionales](#flujos-funcionales)
3. [Detecci√≥n de Bugs Cr√≠ticos](#detecci√≥n-de-bugs-cr√≠ticos)
4. [Mejoras T√©cnicas Recomendadas](#mejoras-t√©cnicas-recomendadas)
5. [Plan de Refactor Priorizado](#plan-de-refactor-priorizado)
6. [Arquitectura Detallada de Servicios](#arquitectura-detallada-de-servicios)

---

## üèóÔ∏è Visi√≥n General de Arquitectura

### Stack ETL (infra/docker-compose.etl.yml)

**Servicios:**
- **Airflow**: Orquesta el pipeline de procesamiento de documentos
- **Kafka**: Sistema de mensajer√≠a para eventos ETL
- **Qdrant**: Base de datos vectorial para embeddings
- **Redis**: Cache para evitar reprocesamiento de URLs
- **Controller Service**: Consume eventos de Kafka y orquesta la segunda fase

**Flujo ETL:**
```
URLs ‚Üí Airflow DAG ‚Üí Chunking PDFs ‚Üí Generaci√≥n Embeddings ‚Üí Carga Qdrant ‚Üí Evento Kafka
```

### Stack RAG (infra/docker-compose.rag.yml)

**Servicios:**
- **Gateway Service**: Punto de entrada para usuarios (FastAPI)
- **LangChains Service**: Orquestador de RAG con LangGraph
- **Embedding Service**: Generaci√≥n de embeddings (SentenceTransformers)
- **LLM Service**: Servicio Ollama con modelo llama3.2:1b
- **Qdrant**: Base de datos vectorial para b√∫squeda sem√°ntica
- **Redis**: ‚úÖ Cache de respuestas e historial de conversaciones (implementado)

**Flujo RAG (Intenci√≥n):**
```
Usuario ‚Üí API Gateway ‚Üí LangChains ‚Üí Embedding Service ‚Üí Qdrant ‚Üí LLM ‚Üí Respuesta
```

---

## üîÑ Flujos Funcionales

### 1. Pipeline ETL de Documentos (Airflow)

**Archivo:** `services/airflow_dags/chunk_and_embedding.py`

**Etapas:**
1. **Lectura de URLs**: Lee desde `urls.txt`
2. **Deduplicaci√≥n**: Usa Redis para evitar reprocesar PDFs ya procesados
3. **Chunking**: Convierte PDFs a Parquet con chunks de texto
4. **Generaci√≥n Embeddings**: Transforma chunks a vectores
5. **Carga Qdrant**: Almacena embeddings en base de datos vectorial
6. **Notificaci√≥n**: Publica evento `etl_done` en Kafka

**Dependencias Externas:**
- `pdf_chunk_flow`: MacroEtlPdfChunks (NO presente en repo)
- `embedding_flow.transform.transform`: transform_embedding (NO presente en repo)
- `embedding_flow.load.load`: load_embedding (NO presente en repo)

‚ö†Ô∏è **Riesgo Alto**: Si estos m√≥dulos no est√°n en la imagen Docker o como plugins, el DAG fallar√°.

### 2. Orquestaci√≥n Post-ETL (Controller Service)

**Archivo:** `services/controller_service/app/main.py`

**Proceso:**
1. Escucha mensajes de Kafka en topic `etl-events`
2. Al recibir `{"event": "etl_done"}`, intenta notificar al gateway
3. Actualmente solo loguea instrucciones manuales para cambiar al stack RAG

**Bug:** Llama a `/start` que no existe en el gateway.

### 3. API Gateway

**Archivo:** `services/api_gateway/app/app.py` y `services/api_gateway/app/routes/routes.py`

**Endpoints:**
- `GET /rag/`: Proxy a servicio RAG (incorrecto, deber√≠a ser POST)
- `WebSocket /rag/chat`: Chat en tiempo real

**Bugs Detectados:**
- Import incorrecto de router
- URL apunta a servicio inexistente (`rag_service:8000`)
- GET endpoint acepta body (antipatr√≥n)

### 4. Servicio LangChains/RAG

**Archivo:** `services/langchains_service/main.py` y `services/langchains_service/chain/rag_chain.py`

**Funcionalidad:**
- Expone `POST /query` con `{"pregunta": "..."}`
- Usa LangGraph para orquestar LLM
- Guarda conversaciones en Qdrant (si colecci√≥n existe)

**‚ö†Ô∏è Problema Cr√≠tico**: **NO implementa RAG real**
- No recupera documentos de Qdrant
- No construye contexto con documentos relevantes
- Solo llama al LLM directamente (conversational, no RAG)

**Configuraci√≥n Qdrant:**
- `DOCS_COLLECTION`: "embeddings_collection" (documentos ETL)
- `CONVERSATIONS_COLLECTION`: "conversations" (opcional)
- Embedding remoto via `embedding_service:8001/embedding`

### 5. Servicio de Embeddings

**Archivo:** `services/embedding_service/app/main.py`

**Funcionalidad:**
- Endpoint: `POST /embedding`
- Modelo: `sentence-transformers/all-mpnet-base-v2`
- Retorna: Lista de vectores (768 dimensiones)

**Limitaciones:**
- Sin validaci√≥n de tama√±o de entrada
- Sin rate limiting
- Sin endpoints de healthcheck

---

## üêõ Detecci√≥n de Bugs Cr√≠ticos

### üî¥ Bugs Cr√≠ticos que Rompen Funcionalidad

#### 1. API Gateway - Import y Registro de Router Incorrecto
**Archivo:** `services/api_gateway/app/app.py`
```python
from routes.routes import queryrag as rag_router  # ‚ùå queryrag es funci√≥n, no router
app.include_router(rag_router, ...)  # ‚ùå Fallar√°
```

**Soluci√≥n:**
```python
from routes.routes import router as rag_router
app.include_router(rag_router, prefix="/rag", tags=["RAG"])
```

#### 2. API Gateway - URL de Servicio Incorrecta
**Archivo:** `services/api_gateway/app/routes/routes.py`
```python
RAG_SERVICE_URL = "http://rag_service:8000/query"  # ‚ùå Servicio no existe
```

**Realidad:**
- Servicio correcto: `langchains_service` (puerto 8002)
- Debe ser: `http://langchains_service:8002/query`

#### 3. API Gateway - Endpoint GET con Body
**Archivo:** `services/api_gateway/app/routes/routes.py`
```python
@router.get("/")  # ‚ùå GET no debe aceptar body
async def queryrag(payload: dict):
```

**Soluci√≥n:** Cambiar a POST con schema Pydantic:
```python
@router.post("/")
async def queryrag(request: QueryRequest):
```

#### 4. LangChains Service - NO Implementa RAG Real
**Archivo:** `services/langchains_service/chain/rag_chain.py`

**Problema:** Falta recuperaci√≥n de documentos relevantes de Qdrant antes de llamar al LLM.

**Soluci√≥n Requerida:**
```python
# Agregar retriever
retriever = qdrant_docs.as_retriever(search_kwargs={"k": 4})
docs = retriever.invoke(question)

# Construir prompt con contexto
context = "\n".join([doc.page_content for doc in docs])
prompt = f"Contexto: {context}\n\nPregunta: {question}"
```

#### 5. Docker Compose - Configuraci√≥n de Env Incorrecta
**Archivo:** `infra/docker-compose.rag.yml`
```yaml
environment:
  - ../environment_variables/.env.rag  # ‚ùå Debe ser env_file
```

**Soluci√≥n:**
```yaml
env_file:
  - ../environment_variables/.env.rag
```

#### 6. Controller Service - Endpoint Inexistente
**Archivo:** `services/controller_service/app/controller.py`
```python
gateway_url = "http://gateway_service:8000/start"  # ‚ùå No existe
```

**Soluci√≥n:** Crear endpoint `/start` en gateway o cambiar a endpoint existente.

#### 7. Airflow DAG - Variable de Entorno Inconsistente
**Archivo:** `services/airflow_dags/chunk_and_embedding.py`
```python
KAFKA_BROKER = os.getenv("KAFKA_BROKER", ...)  # ‚ùå Variable no definida en compose
```

**En docker-compose.etl.yml se define:**
```yaml
KAFKA_BOOTSTRAP_SERVERS: kafka_service:9092
```

**Soluci√≥n:** Alinear nombres de variables.

### üü° Bugs Menores y Mejoras

#### 8. Embedding Service - Sin Validaci√≥n de Input
- Sin l√≠mites de tama√±o de batch
- Riesgo de OOM con lotes grandes

#### 9. Qdrant Schemas - Falta Validaci√≥n de Respuesta
**Archivo:** `services/langchains_service/models/qdrant_schemas.py`
```python
return response.json()[0]  # ‚ùå Asume estructura exacta
```

**Soluci√≥n:** Validar estructura y manejar errores.

#### 10. Falta de Timeouts y Retries
- `httpx.AsyncClient()` sin timeout configurado
- Sin retry logic en llamadas HTTP
- Riesgo de cuelgues en servicios lentos

#### 11. Configuraci√≥n Dispersa
- `core/config.py` est√° vac√≠o
- Constantes hardcodeadas en m√∫ltiples archivos
- Falta uso de `pydantic-settings`

#### 12. Versiones de Dependencias
**Archivo:** `services/langchains_service/requirements.txt`
```
langchain==1.0.2  # ‚ùå Versi√≥n incorrecta (langchain core es 0.x)
```

#### 13. Sin Healthchecks
- Ning√∫n servicio expone `/health`
- Docker healthchecks b√°sicos solo en `llm_service`

#### 14. Logging Inconsistente
- Algunos servicios usan `logging`, otros `print`
- Sin formato est√°ndar
- Falta de niveles apropiados

---

## üîß Mejoras T√©cnicas Recomendadas

### 1. Arquitectura y Contratos entre Servicios

**Problemas:**
- Nombres de servicios inconsistentes entre compose files
- URLs hardcodeadas
- Falta de service discovery

**Soluciones:**
- Usar variables de entorno para todas las URLs
- Implementar service discovery o usar nombres de Docker consistentes
- Documentar contratos de API entre servicios

### 2. Implementaci√≥n Real de RAG

**Estado Actual:**
- LangChains solo llama al LLM sin contexto de documentos

**Mejora Requerida:**
```python
# En rag_chain.py
def generate_answer(question: str, thread_id: str = None) -> str:
    # 1. Recuperar documentos relevantes
    retriever = qdrant_docs.as_retriever(search_kwargs={"k": 4})
    relevant_docs = retriever.invoke(question)
    
    # 2. Construir contexto
    context = "\n\n".join([doc.page_content for doc in relevant_docs])
    
    # 3. Construir prompt con contexto
    prompt = f"""Bas√°ndote en el siguiente contexto, responde la pregunta.
    
Contexto:
{context}

Pregunta: {question}

Respuesta:"""
    
    # 4. Llamar LLM con prompt enriquecido
    result = app.invoke({"messages": [{"role": "user", "content": prompt}]}, ...)
```

### 3. Configuraci√≥n Centralizada

**Crear:** `services/langchains_service/core/config.py`
```python
from pydantic_settings import BaseSettings

class Settings(BaseSettings):
    qdrant_url: str = "http://qdrant:6333"
    qdrant_api_key: str
    embedding_service_url: str = "http://embedding_service:8001/embedding"
    ollama_url: str = "http://llm_service:11434"
    ollama_model: str = "llama3.2:1b"
    docs_collection: str = "embeddings_collection"
    conversations_collection: str = "conversations"
    
    class Config:
        env_file = ".env"
```

### 4. Manejo de Errores y Resiliencia

**Mejoras:**
- Timeouts en todas las llamadas HTTP
- Retry logic con backoff exponencial
- Circuit breakers para servicios externos
- Fallbacks graceful cuando servicios no est√°n disponibles

**Ejemplo:**
```python
import httpx
from tenacity import retry, stop_after_attempt, wait_exponential

@retry(
    stop=stop_after_attempt(3),
    wait=wait_exponential(multiplier=1, min=2, max=10)
)
async def call_embedding_service(texts: list[str]):
    async with httpx.AsyncClient(timeout=30.0) as client:
        response = await client.post(
            EMBEDDING_SERVICE_URL,
            json={"texts": texts},
            timeout=30.0
        )
        response.raise_for_status()
        return response.json()
```

### 5. Validaci√≥n de Inputs

**Embedding Service:**
```python
from pydantic import BaseModel, Field, validator

class EmbeddingRequest(BaseModel):
    texts: list[str] = Field(..., min_items=1, max_items=100)
    
    @validator('texts')
    def validate_texts(cls, v):
        total_chars = sum(len(t) for t in v)
        if total_chars > 100000:  # L√≠mite razonable
            raise ValueError("Batch demasiado grande")
        return v
```

### 6. Observabilidad

**Implementar:**
- Endpoints `/health` y `/ready` en todos los servicios
- M√©tricas Prometheus b√°sicas
- Trazas OpenTelemetry para debugging
- Logging estructurado con niveles apropiados

**Ejemplo Healthcheck:**
```python
@app.get("/health")
async def health():
    return {"status": "healthy"}

@app.get("/ready")
async def ready():
    # Verificar conexi√≥n a Qdrant
    try:
        client.get_collections()
        return {"status": "ready"}
    except Exception:
        return {"status": "not ready"}, 503
```

### 7. Seguridad

**Mejoras:**
- CORS configurado apropiadamente
- Rate limiting en endpoints p√∫blicos
- Validaci√≥n de inputs m√°s estricta
- Secrets management (no hardcodear API keys)

### 8. Testing

**Actual:** Sin tests

**Recomendado:**
- Unit tests para l√≥gica de negocio
- Integration tests para contratos entre servicios
- Tests end-to-end para flujos completos

---

## üìù Plan de Refactor Priorizado

### Fase 1: Correcciones Cr√≠ticas (Bloquean Funcionalidad)

**Prioridad:** üî¥ ALTA

1. **Corregir API Gateway**
   - Arreglar import de router
   - Cambiar GET a POST con schema
   - Corregir URL a `langchains_service:8002`

2. **Corregir Docker Compose RAG**
   - Cambiar `environment` a `env_file` en langchains_service

3. **Implementar RAG Real**
   - Agregar retriever de Qdrant en `rag_chain.py`
   - Construir prompts con contexto de documentos

4. **Alinear Variables de Entorno**
   - Unificar `KAFKA_BROKER` / `KAFKA_BOOTSTRAP_SERVERS`
   - Documentar todas las variables requeridas

### Fase 2: Mejoras de Infraestructura

**Prioridad:** üü° MEDIA

5. **Configuraci√≥n Centralizada**
   - Crear `core/config.py` con pydantic-settings
   - Migrar todas las constantes hardcodeadas

6. **Healthchecks y Observabilidad**
   - Agregar `/health` en todos los servicios
   - Configurar healthchecks en Docker Compose
   - Implementar logging estructurado

7. **Manejo de Errores**
   - Agregar timeouts a todas las llamadas HTTP
   - Implementar retry logic
   - Agregar validaci√≥n de inputs

### Fase 3: Optimizaciones y Mejoras

**Prioridad:** üü¢ BAJA

8. **Validaci√≥n y Rate Limiting**
   - Validar tama√±os de batch en embedding service
   - Implementar rate limiting b√°sico

9. **Documentaci√≥n**
   - Documentar APIs con OpenAPI/Swagger
   - Crear diagramas de arquitectura actualizados
   - Documentar variables de entorno

10. **Testing**
    - Agregar tests unitarios b√°sicos
    - Tests de integraci√≥n para contratos

---

## üèõÔ∏è Arquitectura Detallada de Servicios

### API Gateway (`services/api_gateway/`)

**Stack:** FastAPI + uvicorn

**Responsabilidades:**
- Punto de entrada √∫nico para clientes
- Enrutamiento a servicios backend
- WebSocket para chat en tiempo real

**Endpoints Actuales:**
- `GET /rag/` - Query RAG (incorrecto, debe ser POST)
- `WebSocket /rag/chat` - Chat WebSocket

**Dependencias:**
- `langchains_service:8002`

### LangChains Service (`services/langchains_service/`)

**Stack:** FastAPI + LangGraph + LangChain + Ollama

**Responsabilidades:**
- Orquestar flujo RAG completo
- Gestionar estado de conversaciones
- Integrar LLM con recuperaci√≥n de documentos

**Endpoints:**
- `POST /query` - Query con pregunta

**Dependencias:**
- `embedding_service:8001` - Generaci√≥n de embeddings
- `qdrant:6333` - Base de datos vectorial
- `llm_service:11434` - LLM (Ollama)
- `redis_service:6379` - Cache de respuestas e historial de conversaciones

**Estado Actual:** No implementa RAG real (falta retrieval)

### Embedding Service (`services/embedding_service/`)

**Stack:** FastAPI + SentenceTransformers

**Responsabilidades:**
- Generar embeddings de texto
- Modelo: `all-mpnet-base-v2` (768 dimensiones)

**Endpoints:**
- `POST /embedding` - Generar embeddings de lista de textos

**Limitaciones:**
- Sin validaci√≥n de tama√±o
- Sin rate limiting

### LLM Service (`docker/llm_service/`)

**Stack:** Ollama

**Modelo:** `llama3.2:1b`

**Responsabilidades:**
- Generar respuestas basadas en prompts
- Exponer API compatible con LangChain Ollama

### Controller Service (`services/controller_service/`)

**Stack:** Kafka Consumer + Docker Client

**Responsabilidades:**
- Consumir eventos de Kafka
- Orquestar transici√≥n ETL ‚Üí RAG
- Actualmente solo notifica (no automatiza)

**Eventos Escuchados:**
- `{"event": "etl_done"}` - ETL completado

### Airflow DAG (`services/airflow_dags/`)

**Stack:** Apache Airflow + Confluent Kafka

**DAG:** `chunkear_and_embedding`

**Responsabilidades:**
- Ejecutar pipeline ETL de documentos
- Chunking, embedding, carga a Qdrant
- Publicar eventos en Kafka

**Dependencias Externas (No en repo):**
- `pdf_chunk_flow`
- `embedding_flow.transform.transform`
- `embedding_flow.load.load`

### Qdrant

**Stack:** Qdrant Vector DB

**Colecciones:**
- `embeddings_collection` - Documentos procesados por ETL
- `conversations` (opcional) - Historial de conversaciones

### Redis

**Uso en ETL:**
- Cache de URLs procesadas (set `processed_urls`)

**Uso en RAG:**
- ‚úÖ **IMPLEMENTADO**: Cache de respuestas para preguntas frecuentes
  - Cache autom√°tico de preguntas/respuestas con TTL configurable (default: 1 hora)
  - Clave generada con hash SHA256 de la pregunta normalizada
  - Ubicaci√≥n: `services/langchains_service/models/redis_cache.py`
- ‚úÖ **IMPLEMENTADO**: Historial de conversaciones por `thread_id`
  - Almacena hasta 50 mensajes por conversaci√≥n
  - Expiraci√≥n autom√°tica despu√©s de 7 d√≠as
  - Formato: `conversation:{thread_id}` como lista Redis

---

## üîç An√°lisis de Dependencias

### Dependencias Faltantes en Repositorio

**Cr√≠ticas para ETL:**
- `pdf_chunk_flow` - MacroEtlPdfChunks
- `embedding_flow.transform.transform` - transform_embedding
- `embedding_flow.load.load` - load_embedding

**Soluci√≥n:** Deben estar como:
- Plugins de Airflow en `services/airflow_dags/plugins/`
- O incluidas en la imagen Docker de Airflow

### Variables de Entorno Requeridas

**ETL Stack:**
- `QDRANT_URL`
- `QDRANT_API_KEY`
- `KAFKA_BOOTSTRAP_SERVERS`
- `REDIS_HOST`, `REDIS_PORT`

**RAG Stack:**
- `QDRANT_URL`
- `QDRANT_API_KEY`
- `QDRANT_COLLECTION_DOCS`
- `QDRANT_COLLECTION_CONVERSATIONS`
- `EMBEDDING_SERVICE_URL`
- `OLLAMA_URL`

**Recomendaci√≥n:** Crear `.env.example` con todas las variables documentadas.

---

## üìä Resumen Ejecutivo

### Estado Actual
- ‚úÖ Arquitectura bien dise√±ada conceptualmente
- ‚úÖ Separaci√≥n de servicios apropiada
- ‚ö†Ô∏è Bugs cr√≠ticos que bloquean funcionalidad
- ‚ùå RAG no implementado correctamente
- ‚ùå Falta de tests y validaciones

### Bugs Cr√≠ticos Identificados: 7
1. Import/registro de router incorrecto
2. URL de servicio RAG incorrecta
3. Endpoint GET con body
4. RAG no implementado (solo LLM)
5. Configuraci√≥n env incorrecta en compose
6. Endpoint inexistente en controller
7. Variables de entorno inconsistentes

### Mejoras Recomendadas: 14
- Configuraci√≥n centralizada
- Healthchecks y observabilidad
- Manejo de errores robusto
- Validaci√≥n de inputs
- Rate limiting
- Testing
- Documentaci√≥n

### Esfuerzo Estimado de Refactor
- **Fase 1 (Cr√≠tico):** 1-2 d√≠as
- **Fase 2 (Infraestructura):** 3-5 d√≠as
- **Fase 3 (Optimizaciones):** 5-7 d√≠as

**Total:** ~2 semanas para refactor completo

---

## üöÄ Quick Start (Despu√©s de Correcciones)

### Levantar Stack ETL
```bash
make etl-up
# Acceder a Airflow: http://localhost:8080
```

### Levantar Stack RAG
```bash
make rag-up
# Gateway: http://localhost:8000
# LangChains: http://localhost:8002
```

### Probar RAG (WebSocket)
```javascript
const ws = new WebSocket('ws://localhost:8000/rag/chat');
ws.send('¬øQu√© informaci√≥n tienes disponible?');
```

---

**√öltima Actualizaci√≥n:** Enero 2025  
**Versi√≥n del An√°lisis:** 1.0

